X <- rbind(solTestX, solTrainX)
y <- c(solTestY, solTrainY)
data <- data.frame(Solubility = y, X)
set.seed(1234)
test.id <- sample(1:nrow(X), size = .2*nrow(X)) ## Randomly choose 20% of rows for test set
test.data <- data[test.id,]  ## Subset to include rows designated to test set
train.data <- data[-test.id,]  ## Exclude rows designated to test set
P <- prcomp(train.data[,210:ncol(train.data)], scale = TRUE)
train.data2 <- data.frame(Solubility = train.data$Solubility, P$x[,1:8])
set.seed(15)
pls.fit <- train(Solubility ~ .,  data = train.data[,c(1,210:ncol(train.data))], method = "pls", trControl = fit.control, tuneGrid = data.frame(ncomp = 1:20))
pls.fit
library(caret)
library(AppliedPredictiveModeling)
library(factoextra)
data(solubility)
X <- rbind(solTestX, solTrainX)
y <- c(solTestY, solTrainY)
data <- data.frame(Solubility = y, X)
set.seed(1234)
test.id <- sample(1:nrow(X), size = .2*nrow(X)) ## Randomly choose 20% of rows for test set
test.data <- data[test.id,]  ## Subset to include rows designated to test set
train.data <- data[-test.id,]  ## Exclude rows designated to test set
P <- prcomp(train.data[,210:ncol(train.data)], scale = TRUE)
train.data2 <- data.frame(Solubility = train.data$Solubility, P$x[,1:8])
set.seed(15)
pls.fit <- train(Solubility ~ .,  data = train.data[,c(1,210:ncol(train.data))], method = "pls", trControl = fit.control, tuneGrid = data.frame(ncomp = 1:20))
library(caret)
library(AppliedPredictiveModeling)
library(factoextra)
data(solubility)
X <- rbind(solTestX, solTrainX)
y <- c(solTestY, solTrainY)
data <- data.frame(Solubility = y, X)
set.seed(1234)
test.id <- sample(1:nrow(X), size = .2*nrow(X)) ## Randomly choose 20% of rows for test set
test.data <- data[test.id,]  ## Subset to include rows designated to test set
train.data <- data[-test.id,]  ## Exclude rows designated to test set
P <- prcomp(train.data[,210:ncol(train.data)], scale = TRUE)
train.data2 <- data.frame(Solubility = train.data$Solubility, P$x[,1:8])
fit.control = trainControl(method = "repeatedcv", number = 5, repeats = 10)
set.seed(15)
pls.fit <- train(Solubility ~ .,  data = train.data[,c(1,210:ncol(train.data))], method = "pls", trControl = fit.control, tuneGrid = data.frame(ncomp = 1:20))
pls.fit
ggplot(pls.fit)
library(caret)
library(AppliedPredictiveModeling)
library(factoextra)
data(solubility)
X <- rbind(solTestX, solTrainX)
y <- c(solTestY, solTrainY)
data <- data.frame(Solubility = y, X)
set.seed(1234)
test.id <- sample(1:nrow(X), size = .2*nrow(X)) ## Randomly choose 20% of rows for test set
test.data <- data[test.id,]  ## Subset to include rows designated to test set
train.data <- data[-test.id,]  ## Exclude rows designated to test set
P <- prcomp(train.data[,210:ncol(train.data)], scale = TRUE)
train.data2 <- data.frame(Solubility = train.data$Solubility, P$x[,1:8])
library(tidyr)
P$rotation[,4]
## We will evaluate models using repeated cross validation
fit.control = trainControl(method = "repeatedcv", number = 5, repeats = 10)
## Find original vars most correlated with solubility
cors <- cor(train.data[,c(1,210:ncol(train.data))])
cors[,1]
## Specify a model using the two most correlated vars
model1 <- formula(Solubility ~ MolWeight + NumCarbon)
## Fit model1
set.seed(15)
fit.lm1 <- train(model1, data = train.data, method = "lm", trControl = fit.control)
## Model using the first two principle components
model2 <- formula(Solubility ~ PC1 + PC2)
set.seed(15)
fit.lm2 <- train(model2, data = train.data2, method = "lm", trControl = fit.control)
## Compare these two models
library(tidyr)
model3 <- formula(Solubility ~ PC1 + PC2 + PC3)
model4 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4)
## The poly function can be used to add non-linear effects
model4q <- formula(Solubility ~ PC1 + PC2 + PC3 + poly(PC4, degree = 2))
set.seed(15)
fit.lm3 <- train(model3, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm4 <- train(model4, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm4q <- train(model4q, data = train.data2, method = "lm", trControl = fit.control)
model5 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5)
model6 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6)
model7 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7)
model8 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8)
set.seed(15)
fit.lm5 <- train(model5, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm6 <- train(model6, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm7 <- train(model7, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm8 <- train(model8, data = train.data2, method = "lm", trControl = fit.control)
## Compare these new models
# resamps <- resamples(list(lm2 = fit.lm2, lm3 = fit.lm3, lm4 = fit.lm4, lm5 = fit.lm5,
#                           lm6 = fit.lm6, lm7 = fit.lm7, lm8 = fit.lm8))
# resamps2 <- gather(resamps$values, key = "Var", value = "Val", 2:ncol(resamps$values))
# resamps2 <- separate(resamps2, col = "Var", into = c("Model", "Metric"), sep = "~")
#
# ggplot(resamps2, aes(x = Model, y = Val)) + geom_boxplot() + facet_wrap(~ Metric, scales = "free")
resamps <- resamples(list(lm6 = fit.lm6, lm7 = fit.lm7, lm8 = fit.lm8))
resamps2 <- gather(resamps$values, key = "Var", value = "Val", 2:ncol(resamps$values))
resamps2 <- separate(resamps2, col = "Var", into = c("Model", "Metric"), sep = "~")
ggplot(resamps2, aes(x = Model, y = Val)) + geom_boxplot() + facet_wrap(~ Metric, scales = "free")
View(data)
library(caret)
library(AppliedPredictiveModeling)
library(factoextra)
data(solubility)
X <- rbind(solTestX, solTrainX)
y <- c(solTestY, solTrainY)
data <- data.frame(Solubility = y, X)
set.seed(1234)
test.id <- sample(1:nrow(X), size = .2*nrow(X)) ## Randomly choose 20% of rows for test set
test.data <- data[test.id,]  ## Subset to include rows designated to test set
train.data <- data[-test.id,]  ## Exclude rows designated to test set
P <- prcomp(train.data[,210:ncol(train.data)], scale = TRUE)
train.data2 <- data.frame(Solubility = train.data$Solubility, P$x[,1:8])
library(tidyr)
P$rotation[,4]
## We will evaluate models using repeated cross validation
fit.control = trainControl(method = "repeatedcv", number = 5, repeats = 10)
## Find original vars most correlated with solubility
cors <- cor(train.data[,c(1,210:ncol(train.data))])
cors[,1]
## Specify a model using the two most correlated vars
model1 <- formula(Solubility ~ MolWeight + NumCarbon)
## Fit model1
set.seed(15)
fit.lm1 <- train(model1, data = train.data, method = "lm", trControl = fit.control)
## Model using the first two principle components
model2 <- formula(Solubility ~ PC1 + PC2)
set.seed(15)
fit.lm2 <- train(model2, data = train.data2, method = "lm", trControl = fit.control)
## Compare these two models
library(tidyr)
model3 <- formula(Solubility ~ PC1 + PC2 + PC3)
model4 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4)
## The poly function can be used to add non-linear effects
model4q <- formula(Solubility ~ PC1 + PC2 + PC3 + poly(PC4, degree = 2))
set.seed(15)
fit.lm3 <- train(model3, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm4 <- train(model4, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm4q <- train(model4q, data = train.data2, method = "lm", trControl = fit.control)
model5 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5)
model6 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6)
model7 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7)
model8 <- formula(Solubility ~ PC1 + PC2 + PC3 + PC4 + PC5 + PC6 + PC7 + PC8)
set.seed(15)
fit.lm5 <- train(model5, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm6 <- train(model6, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm7 <- train(model7, data = train.data2, method = "lm", trControl = fit.control)
set.seed(15)
fit.lm8 <- train(model8, data = train.data2, method = "lm", trControl = fit.control)
## Compare these new models
# resamps <- resamples(list(lm2 = fit.lm2, lm3 = fit.lm3, lm4 = fit.lm4, lm5 = fit.lm5,
#                           lm6 = fit.lm6, lm7 = fit.lm7, lm8 = fit.lm8))
# resamps2 <- gather(resamps$values, key = "Var", value = "Val", 2:ncol(resamps$values))
# resamps2 <- separate(resamps2, col = "Var", into = c("Model", "Metric"), sep = "~")
#
# ggplot(resamps2, aes(x = Model, y = Val)) + geom_boxplot() + facet_wrap(~ Metric, scales = "free")
set.seed(15)
pls.fit <- train(Solubility ~ .,  data = train.data[,c(1,210:ncol(train.data))], method = "pls", trControl = fit.control, tuneGrid = data.frame(ncomp = 1:20))
resamps <- resamples(list(pls_fit = pls.fit, lm6 = fit.lm6, lm7 = fit.lm7, lm8 = fit.lm8))
resamps2 <- gather(resamps$values, key = "Var", value = "Val", 2:ncol(resamps$values))
resamps2 <- separate(resamps2, col = "Var", into = c("Model", "Metric"), sep = "~")
ggplot(resamps2, aes(x = Model, y = Val)) + geom_boxplot() + facet_wrap(~ Metric, scales = "free")
library(openNLP)
library(NLP)
tagged_text <- tagPOS(corp[[1]])
library(NLP)
tagged_text <- tagPOS(corp[[1]])
library(openNLP)
install.packages(NLP)
install.packages("NLP")
install.packages("NLP")
library(NLP)
library(openNLP)
install.packages("rJava")
library(rJava)
library(rJava)
library(openNLP)
library(tm)
library(NLP)
tagged_text <- tagPOS(corp[[1]])
library(openNLP)
Sys.getenv("JAVA_HOME")
Sys.getenv("Path")
sessionInfo()
library(openNLP)
library(rJava)
??SelectTaggedWords
library(tm)
library(NLP)
install.packages("udpipe")
library(udpipe)
install.packages("textrank")
library(textrank)
data(brussels_reviews)
data(brussels_reviews)
View(brussels_reviews)
comments <- subset(brussels_reviews, language %in% "es")
View(comments)
ud_model <- udpipe_download_model(language = "spanish")
ud_model <- udpipe_load_model(ud_model$file_model)
View(ud_model)
x <- udpipe_annotate(ud_model, x = comments$feedback)
x <- as.data.frame(x)
x
View(x)
stats <- subset(x, upos %in% "NOUN")
stats <- txt_freq(x = stats$lemma)
library(lattice)
stats$key <- factor(stats$key, levels = rev(stats$key))
View(stats)
stats <- subset(x, upos %in% "NOUN")
View(stats)
export JAVA_HOME="/usr/libexec/java_home -v 1.8"
export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/server
options("java.home"="/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/jre")
library(openNLP)
tagged_text <- tagPOS(corp[[1]])
tagPOS <-  function(x, ...) {
s <- as.String(x)
word_token_annotator <- Maxent_Word_Token_Annotator()
a2 <- Annotation(1L, "sentence", 1L, nchar(s))
a2 <- annotate(s, word_token_annotator, a2)
a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
a3w <- a3[a3$type == "word"]
POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
list(POStagged = POStagged, POStags = POStags)
}
tagged_text <- tagPOS(corp[[1]])
library(tm)
library(NLP)
library(openNLP)
install.packages("rJava")
library(rJava)
doc <- c("Compatibility of systems
of linear constraints over the
set of natural numbers.
Criteria of compatibility of a system
of linear Diophantine equations, strict
inequations, and nonstrict inequations
are considered. Upper bounds for components
of a minimal set of solutions and algorithms of
construction of minimal generating sets of solutions
for all types of systems are given. These criteria
and the corresponding algorithms for constructing
a minimal supporting set of solutions can be used
in solving all the considered  types systems and
systems of mixed types.")
#Creating corpus
corp <- Corpus(VectorSource(doc))
# Text Tokeization
SplitText <- function(Phrase) {
unlist(strsplit(Phrase," "))
}
# To check if word is present in word list
IsSelectedWord <- function(Word) {
ifelse(length(which(selected_words == Word))>0, TRUE, FALSE)
}
# Pre-Processing
corp <- tm_map(corp, stripWhitespace) # removing extra spaces (keeping only single space)
corp <- tm_map(corp, tolower) # transforming to lower case
words_with_punctuation <- SplitText(as.character(corp[[1]]))
corp <- tm_map(corp, removePunctuation)
# GRAPH CONSTRUCTION
tagPOS <-  function(x, ...) {
s <- as.String(x)
word_token_annotator <- Maxent_Word_Token_Annotator()
a2 <- Annotation(1L, "sentence", 1L, nchar(s))
a2 <- annotate(s, word_token_annotator, a2)
a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
a3w <- a3[a3$type == "word"]
POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
list(POStagged = POStagged, POStags = POStags)
}
words <- SplitText(as.character(corp[[1]])) # tokenization
tagged_text <- tagPOS(corp[[1]])
tagged_words <- SplitText(as.character(tagged_text))
#Creating corpus
corp <- Corpus(VectorSource(doc))
# Text Tokeization
SplitText <- function(Phrase) {
unlist(strsplit(Phrase," "))
}
# Pre-Processing
corp <- tm_map(corp, stripWhitespace) # removing extra spaces (keeping only single space)
corp <- tm_map(corp, tolower) # transforming to lower case
words_with_punctuation <- SplitText(as.character(corp[[1]]))
corp <- tm_map(corp, removePunctuation)
tagPOS <-  function(x, ...) {
s <- as.String(x)
word_token_annotator <- Maxent_Word_Token_Annotator()
a2 <- Annotation(1L, "sentence", 1L, nchar(s))
a2 <- annotate(s, word_token_annotator, a2)
a3 <- annotate(s, Maxent_POS_Tag_Annotator(), a2)
a3w <- a3[a3$type == "word"]
POStags <- unlist(lapply(a3w$features, `[[`, "POS"))
POStagged <- paste(sprintf("%s/%s", s[a3w], POStags), collapse = " ")
list(POStagged = POStagged, POStags = POStags)
}
words <- SplitText(as.character(corp[[1]])) # tokenization
tagged_text <- tagPOS(corp[[1]])
View(stats)
data = "As in any market, financial markets are characterized by buyers and sellers. We are most familiar with
commodity markets where buyers and sellers exchange money for a commodity like an apple or a book.
Financial markets are structured around the sale/purchase of a security: a financial instrument like a
stock, a bond, a derivative, a collateralized debt obligation (CDO), etc. At heart, most of these
instruments are designed to move money from one time period to another. For example, a firm will sell
a stock or a share of its ownership: in exchange for giving the firm money today, I own a piece of the
company which will return money (profit) tomorrow. Or, a firm will sell a bond: in exchange for giving
the firm money today, the firm promises to pay me back my principal (with interest) tomorrow. "
ud_model <- udpipe_download_model(language = "english")
library(udpipe)
library(textrank)
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, data)
x <- as.data.frame(x)
stats <- subset(x, upos %in% "NOUN")
stats <- txt_freq(x = stats$lemma)
stats$key <- factor(stats$key, levels = rev(stats$key))
data = c(data1,data2)
data2 = "Since the future is uncertain, finance is inherently a risky proposition. By its very nature, financial
markets are risky. A fundamental tension in finance, then, is how to balance this risk with reward. That
is, if an investor is going to accept a riskier proposition, they need to be compensated with a higher
reward (a higher dividend or firm profit in the case of a stock; a higher interest rate in the case of a
bond, etc.). Rather than a problem, this risk/reward trade-off is an inherent feature of financial
markets. The evolution of financial markets and the generation of ever more complex financial
instruments attempt to deal with this risk/reward trade-off in more sophisticated ways."
data = c(data1,data2)
data1 = "As in any market, financial markets are characterized by buyers and sellers. We are most familiar with
commodity markets where buyers and sellers exchange money for a commodity like an apple or a book.
Financial markets are structured around the sale/purchase of a security: a financial instrument like a
stock, a bond, a derivative, a collateralized debt obligation (CDO), etc. At heart, most of these
instruments are designed to move money from one time period to another. For example, a firm will sell
a stock or a share of its ownership: in exchange for giving the firm money today, I own a piece of the
company which will return money (profit) tomorrow. Or, a firm will sell a bond: in exchange for giving
the firm money today, the firm promises to pay me back my principal (with interest) tomorrow. "
data = c(data1,data2)
x <- udpipe_annotate(ud_model, data)
x <- as.data.frame(x)
stats <- subset(x, upos %in% "NOUN")
View(stats)
stats <- txt_freq(x = stats$lemma)
View(stats)
stats <- textrank_keywords(x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
ngram_max = 8, sep = " ")
stats <- subset(stats$keywords, ngram > 1 & freq >= 5)
install.packages("worldcloud")
library(wordcloud)
linstall.packages("wordcloud")
install.packages("wordcloud")
library(wordcloud)
wordcloud(words = stats$keyword, freq = stats$freq)
stats <- subset(stats$keywords, ngram > 1 & freq >= 5)
stats <- subset(stats$keywords, ngram > 1 & freq >= 5)
stats <- textrank_keywords(x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
ngram_max = 8, sep = " ")
stats <- subset(stats$keywords, ngram > 1 & freq >= 5)
wordcloud(words = stats$keyword, freq = stats$freq)
library(udpipe)
library(textrank)
data1 = "As in any market, financial markets are characterized by buyers and sellers. We are most familiar with
commodity markets where buyers and sellers exchange money for a commodity like an apple or a book.
Financial markets are structured around the sale/purchase of a security: a financial instrument like a
stock, a bond, a derivative, a collateralized debt obligation (CDO), etc. At heart, most of these
instruments are designed to move money from one time period to another. For example, a firm will sell
a stock or a share of its ownership: in exchange for giving the firm money today, I own a piece of the
company which will return money (profit) tomorrow. Or, a firm will sell a bond: in exchange for giving
the firm money today, the firm promises to pay me back my principal (with interest) tomorrow. "
data2 = "Since the future is uncertain, finance is inherently a risky proposition. By its very nature, financial
markets are risky. A fundamental tension in finance, then, is how to balance this risk with reward. That
is, if an investor is going to accept a riskier proposition, they need to be compensated with a higher
reward (a higher dividend or firm profit in the case of a stock; a higher interest rate in the case of a
bond, etc.). Rather than a problem, this risk/reward trade-off is an inherent feature of financial
markets. The evolution of financial markets and the generation of ever more complex financial
instruments attempt to deal with this risk/reward trade-off in more sophisticated ways."
data = c(data1,data2)
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, data)
x <- as.data.frame(x)
stats <- textrank_keywords(x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
ngram_max = 8, sep = " ")
stats <- subset(stats$keywords, ngram > 1 & freq >= 5)
library(wordcloud)
wordcloud(words = stats$keyword, freq = stats$freq)
stats <- textrank_keywords(x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
ngram_max = 8, sep = " ")
x <- as.data.frame(x)
stats <- textrank_keywords(x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
ngram_max = 8, sep = " ")
x <- udpipe_annotate(ud_model, data)
x <- as.data.frame(x)
stats <- textrank_keywords(x$lemma,
relevant = x$upos %in% c("NOUN", "ADJ"),
ngram_max = 8, sep = " ")
stats <- subset(x, upos %in% c("NOUN","ADJ"))
stats <- txt_freq(x = stats$lemma)
wordcloud(words = stats$keyword, freq = stats$freq)
y = wordcloud(words = stats$keyword, freq = stats$freq)
y = wordcloud(words = stats$keyword, freq = stats$freq)
y
y = wordcloud(words = stats$keyword, freq = stats$freq,min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
y = wordcloud(words = stats$keyword, freq = stats$freq,min.freq = 1,
max.words=200,
colors=brewer.pal(8, "Dark2"))
y = wordcloud(words = stats$key, freq = stats$freq,
min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
library(udpipe)
library(textrank)
data1 = "As in any market, financial markets are characterized by buyers and sellers. We are most familiar with
commodity markets where buyers and sellers exchange money for a commodity like an apple or a book.
Financial markets are structured around the sale/purchase of a security: a financial instrument like a
stock, a bond, a derivative, a collateralized debt obligation (CDO), etc. At heart, most of these
instruments are designed to move money from one time period to another. For example, a firm will sell
a stock or a share of its ownership: in exchange for giving the firm money today, I own a piece of the
company which will return money (profit) tomorrow. Or, a firm will sell a bond: in exchange for giving
the firm money today, the firm promises to pay me back my principal (with interest) tomorrow. "
data2 = "Since the future is uncertain, finance is inherently a risky proposition. By its very nature, financial
markets are risky. A fundamental tension in finance, then, is how to balance this risk with reward. That
is, if an investor is going to accept a riskier proposition, they need to be compensated with a higher
reward (a higher dividend or firm profit in the case of a stock; a higher interest rate in the case of a
bond, etc.). Rather than a problem, this risk/reward trade-off is an inherent feature of financial
markets. The evolution of financial markets and the generation of ever more complex financial
instruments attempt to deal with this risk/reward trade-off in more sophisticated ways."
data3 = "As you may recall, when we find that we have written similar procedures, we should write a procedure that generalizes the common aspects of those procedures, making any differences parameters to that procedure.
What is similar between all of these procedures? They all check if the parameter is a list and, if so, map the same procedure over that list and then do something with the result. They all do something with the parameter if it’s not a list, even if that “something” is “just leave the parameter as is”.
a. Document a procedure, deep-fun, that encapsulates the common aspects of deep-reverse, deep-largest, and deep-tally-odd
b. Write the deep-fun procedure.
c. Rewrite deep-reverse, deep-largest, and deep-tally-odd so that they use deep-fun to do most of the work.
d. Using deep-fun, write (deep-tally pred? val), a generalized version of deep-tally-odd that tallies the number of values for which the predicate holds.
"
data = c(data1,data2,data3)
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
x <- udpipe_annotate(ud_model, data)
x <- as.data.frame(x)
stats <- subset(x, upos %in% c("NOUN","ADJ"))
library(wordcloud)
wordcloud(words = stats$keyword, freq = stats$freq)
stats <- txt_freq(x = stats$lemma)
y = wordcloud(words = stats$key, freq = stats$freq,
min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
top10 = stats$key[0:10]
top10
df  <- dget("out")
df  <- dget(~Downloads/out)
df  <- dget(~Downloads/"out")
df  <- dget("~Downloads/out")
df = read.csv("~/Download/out.csv")
df = read.csv("~/Download/steam-all-games.csv")
df = read.csv("~/Downloads/out.csv")
df = read.csv("~/Downloads/out.jpg")
df = dget("~/Downloads/out.jpg")
df = dput("~/Downloads/out.jpg")
df
df = dget("~/Downloads/out.jpg")
df = dget("~/Downloads/out”)
df = dget("~/Downloads/out")
df = dget("~Downloads/out")
shiny::runApp('finalProject')
library(udpipe)
library(textrank)
library(stringr)
str_data = read.delim("~/Downloads/games.txt")
str_data$date = format(as.Date(str_data$date), "%Y")
str_data$date = as.numeric(str_data$date)
str_data$tags = as.character(str_data$tags)
str_data$title = as.character(str_data$title)
str_data$description = as.character(str_data$description)
str_data$reviews = as.character(str_data$reviews)
sample_datat = str_data$reviews[grep("RPG", as.character(str_data$tags))]
sample_datat1 = str_data$reviews[grep("Action", as.character(str_data$tags))]
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
sample_x1 = udpipe_annotate(ud_model,sample_datat1)
sample_x1 <- as.data.frame(sample_x1)
sample_stats1 <- subset(sample_x1, upos %in% c("NOUN"))
sample_stats1 <- txt_freq(x = sample_stats1$lemma)
library(wordcloud)
wc1 = wordcloud(words = sample_stats1$key, freq = sample_stats1$freq,
min.freq = 1,
max.words=200, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
runApp('finalProject')
shiny::runApp()
